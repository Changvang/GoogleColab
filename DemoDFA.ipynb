{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoDFA.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1zAVMalCDfpCzAVQ0-jRRWUBQVMxsWVSC",
      "authorship_tag": "ABX9TyPWRvTVMOguXCs9FmllUC57",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Changvang/GoogleColab/blob/main/DemoDFA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE85nM5IKFew"
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim import corpora, models\n",
        "\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLod6pi7qaBr"
      },
      "source": [
        "# Load data set with 2150 Kaggle dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_aSRPoFCIcr"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load data set with 2150 Kaggle dataset\n",
        "dataset = pd.read_csv('drive/My Drive/Colab Notebooks/dataset/voted-kaggle-dataset.csv')\n",
        "print(dataset.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2488mi_zKxQW"
      },
      "source": [
        "dataset.iloc[0:5,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R-75s3zL-1z"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvv60gmHMge1"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhoDD-o3GNJ9"
      },
      "source": [
        "dataset.columns.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aUfc7YAMnKB"
      },
      "source": [
        "modified_dataset = dataset.loc[:, ['Title', 'Subtitle', 'Description']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJzy11SSQy71"
      },
      "source": [
        "modified_dataset.iloc[0:5,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imiIR7VhQ5ZZ"
      },
      "source": [
        "modified_dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4SpoO71RSsp"
      },
      "source": [
        "modified_dataset.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CVnZj8MReH1"
      },
      "source": [
        "# some row will no data\n",
        "print(modified_dataset.isnull().sum())\n",
        "print(\"total null values: \", sum(modified_dataset.isnull().values.ravel()))\n",
        "print(\"total number of rows containing null values: \", sum([True for idx,row in modified_dataset.iterrows() if any(row.isnull())]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtffH419WDSH"
      },
      "source": [
        "#remove rows have null value\n",
        "modified_dataset = modified_dataset.dropna()\n",
        "modified_dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avc-ueRPXcjZ"
      },
      "source": [
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNljbW0OXzC5"
      },
      "source": [
        "\n",
        "\n",
        "# Remove stropword, puncation and lower casing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4374L5wzXhVb"
      },
      "source": [
        "remove_digits = str.maketrans('', '' , string.digits)\n",
        "# three arguments so all value in third argument will assign to None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2NSmlBkZnR4"
      },
      "source": [
        "for column in ['Title', 'Subtitle','Description']:\n",
        "  #lower all string\n",
        "  modified_dataset[column] = modified_dataset[column].map(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2mq5ifiapoD"
      },
      "source": [
        "modified_dataset.iloc[0:3,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TotXKY5sKH5"
      },
      "source": [
        "exclude = '[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z1IJUdfxbH-"
      },
      "source": [
        "for column in ['Title','Subtitle','Description']:\n",
        "  # Delete digits\n",
        "  modified_dataset[column] = modified_dataset[column].map(lambda x : x.translate(remove_digits))\n",
        "  # Delete punctation\n",
        "  modified_dataset[column] = modified_dataset[column].map(lambda x : re.sub(str(exclude), '', x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BC4Y_pIyquS"
      },
      "source": [
        "modified_dataset.iloc[0:3,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChdC3zYEzAEz"
      },
      "source": [
        "\n",
        "# Using stemming and lemmalization for preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP00YLl_yyto"
      },
      "source": [
        "# Tag is a main title of this document\n",
        "tag_dataset = dataset['Tags']\n",
        "tag_dataset.isnull().sum()\n",
        "#tag_dataset=tag_dataset.dropna()\n",
        "tag_dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF4GeU1oy5mn"
      },
      "source": [
        "print(len(tag_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66-MHD6dzlPX"
      },
      "source": [
        "def convert(lst): \n",
        "    return (lst.split(\"\\n\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU5y4VaIznDk"
      },
      "source": [
        "unique_tag = []\n",
        "for i in range(len(tag_dataset)):\n",
        "  tag_string = str(tag_dataset[i])\n",
        "  if tag_string != \"nan\" :\n",
        "    tag_word=convert(tag_string)\n",
        "    for j in range(len(tag_word)):\n",
        "      if tag_word[j] not in unique_tag:\n",
        "        unique_tag.append(tag_word[j])\n",
        "print(len(unique_tag))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIXnVoazhwuE"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "tokenized_dataframe = modified_dataset.apply(lambda row: nltk.word_tokenize(row['Description']), axis = 1)\n",
        "print(type(tokenized_dataframe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrsqMM2ni2r3"
      },
      "source": [
        "print(tokenized_dataframe[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onMUSSw54RYD"
      },
      "source": [
        "#check single word\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrfyNc-YE1ri"
      },
      "source": [
        "def lemmatize_text(text):\n",
        "    return  [ps.stem(w) for w in text if len(w)>5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_wzKi2wHx5S"
      },
      "source": [
        "stemmed_dataset = tokenized_dataframe.apply(lemmatize_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_2c_d0wINJr"
      },
      "source": [
        "stemmed_dataset[0:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRsN9I0iId52"
      },
      "source": [
        "#Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alYMcqeEIkBY"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset_words=''.join(list(str(stemmed_dataset.values)))\n",
        "print(type(dataset_words))\n",
        "wordcloud = WordCloud(width = 800, height = 500, \n",
        "                background_color ='white',  \n",
        "                min_font_size = 10).generate(dataset_words) \n",
        "\n",
        "plt.figure(figsize = (5, 5), facecolor = None) \n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\") \n",
        "plt.tight_layout(pad = 0) \n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kEsqhJdLqcl"
      },
      "source": [
        "# Create Dictionary and Corpus for LDA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryZJSSOxLxi0"
      },
      "source": [
        "dictionary_of_words =gensim.corpora.Dictionary(stemmed_dataset)\n",
        "print(len(dictionary_of_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s36gEnfMGJ4"
      },
      "source": [
        "print(dictionary_of_words.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coF3JY6-NBup"
      },
      "source": [
        "word_corpus = [dictionary_of_words.doc2bow(word) for word in stemmed_dataset]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaDvOlIeNSla"
      },
      "source": [
        "print(word_corpus[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyd6jkh4tseO"
      },
      "source": [
        "# Training the first model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bAZcA4nWAUH"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=word_corpus,\n",
        "    id2word=dictionary_of_words,\n",
        "    num_topics=50,\n",
        "    random_state=101,\n",
        "    update_every=1,\n",
        "    chunksize=300,\n",
        "    passes=50,\n",
        "    alpha='auto',\n",
        "    per_word_topics=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm3w9OeZjoWw"
      },
      "source": [
        "#print(lda_model.print_topics(-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nLfqscMj0cv"
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-xBRQAUkApf"
      },
      "source": [
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "coherence_val = CoherenceModel(model=lda_model, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n",
        "\n",
        "print('Coherence Score: ', coherence_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aESy2nX8k7Cu"
      },
      "source": [
        "models = []\n",
        "coherence_value = []\n",
        "for topic_number in range(10,100,10):\n",
        "  lda_model = gensim.models.ldamodel.LdaModel(corpus=word_corpus,\n",
        "                                           id2word=dictionary_of_words,\n",
        "                                           num_topics=topic_number, \n",
        "                                           random_state=101,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=50,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "  models.append(lda_model)\n",
        "  coherence_model_lda = CoherenceModel(model=lda_model, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v')\n",
        "  coherence_lda = coherence_model_lda.get_coherence()\n",
        "  coherence_value.append(coherence_lda)\n",
        "  print(\"number of topics \",topic_number,\"coherence_value :\" , coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsyjK4TryQ8g"
      },
      "source": [
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "\n",
        "# # Compute Coherence Score\n",
        "# cohr_val = CoherenceModel(model=lda_model, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n",
        "\n",
        "# print('\\nCoherence Score: ', cohr_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC5JrPrq5Tnz"
      },
      "source": [
        "\n",
        "# Support multi core genshin lda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-io0I9HOyZJ1"
      },
      "source": [
        "from gensim.test.utils import common_corpus, common_dictionary\n",
        "lda_multicore_model = gensim.models.ldamulticore.LdaMulticore(corpus=word_corpus, \n",
        "                                                              num_topics=50, \n",
        "                                                              id2word=dictionary_of_words,                                                             \n",
        "                                                              chunksize=100, \n",
        "                                                              passes=50,                                \n",
        "                                                              alpha='symmetric',\n",
        "                                                              eta=0.1,\n",
        "                                                              decay=0.5, \n",
        "                                                              offset=1.0, \n",
        "                                                              gamma_threshold=0.001,\n",
        "                                                              random_state=101,\n",
        "                                                              minimum_probability=0.01,\n",
        "                                                              minimum_phi_value=0.01,\n",
        "                                                              per_word_topics=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H238aWPbyrEq"
      },
      "source": [
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "\n",
        "# Compute Coherence Score\n",
        "cohr_lda_multicore_model1 = CoherenceModel(model=lda_multicore_model, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n",
        "\n",
        "print('\\nCoherence Score: ', cohr_lda_multicore_model1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U8FvWZW3wgt"
      },
      "source": [
        "# from gensim.test.utils import common_corpus, common_dictionary\n",
        "# lda_multicore_model2 = gensim.models.ldamulticore.LdaMulticore(corpus=word_corpus, \n",
        "#                                                               num_topics=319, \n",
        "#                                                               id2word=dictionary_of_words,                                                             \n",
        "#                                                               chunksize=100, \n",
        "#                                                               passes=50,                                \n",
        "#                                                               alpha='symmetric',\n",
        "#                                                               eta=0.1,\n",
        "#                                                               decay=0.5, \n",
        "#                                                               offset=1.0, \n",
        "#                                                               gamma_threshold=0.001,\n",
        "#                                                               random_state=101,\n",
        "#                                                               minimum_probability=0.01,\n",
        "#                                                               minimum_phi_value=0.01,\n",
        "#                                                               per_word_topics=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmdffcYO4AMs"
      },
      "source": [
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "\n",
        "# # Compute Coherence Score\n",
        "# cohr_lda_multicore_model2 = CoherenceModel(model=lda_multicore_model2, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n",
        "\n",
        "# print('\\nCoherence Score: ', cohr_lda_multicore_model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvk_j-OSC901"
      },
      "source": [
        "# Find topic in a document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM-uxcR6vmQ_"
      },
      "source": [
        "v = lda_model[word_corpus[2]]\n",
        "print(type(lda_model[word_corpus[2]]))\n",
        "z=sorted(v[0], key=lambda tup: -1*tup[1])\n",
        "print(z)\n",
        "print(v[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhLxuSeMvqm5"
      },
      "source": [
        "for  index,score in sorted(lda_model[word_corpus[2]][0], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9zQPhY4vyLy"
      },
      "source": [
        "topics = lda_model.show_topics(formatted=False)\n",
        "topic_words = dict(topics[0][1])\n",
        "wordcloud.generate_from_frequencies(topic_words, max_font_size=100)\n",
        "plt.figure(figsize = (5, 5), facecolor = None) \n",
        "plt.title(\"topic 0\")\n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\") \n",
        "plt.tight_layout(pad = 0) \n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdP_7ViHv1wg"
      },
      "source": [
        "fig = plt.figure(figsize=(15,15),frameon=0)\n",
        "a = fig.add_subplot(1, 2, 1)\n",
        "topic_words = dict(topics[1][1])\n",
        "wordcloud.generate_from_frequencies(topic_words, max_font_size=100)\n",
        "imgplot = plt.imshow(wordcloud)\n",
        "a.set_title('topic 0')\n",
        "\n",
        "a = fig.add_subplot(1, 2, 2)\n",
        "topic_words = dict(topics[2][1])\n",
        "wordcloud.generate_from_frequencies(topic_words, max_font_size=100)\n",
        "imgplot = plt.imshow(wordcloud)\n",
        "\n",
        "a.set_title('topic 1')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}